# 第二次实验报告

# 一、实验目标

​		本实验以 Kaggle 的相关数据集为基础，依据 2012 至 2015 年间世界大学排名中心 (CWUR) 的排名数据构建线性回归模型来预测一所大学的综合得分。

​		本实验报告中所有代码均为示例代码，为了叙述清晰，部分是从函数、类中粘贴出来，不保证单独可以正确执行。各小节所使用脚本在相应小节开头有所标注。脚本注释较少，作用及结论请以实验报告为准。作者所使用的环境是 MacOS 12.2.1，Python 3.9，PyCharm 2021.3.1，能正确运行各脚本。



# 二、数据描述与处理

### 2.1 去除缺失数据

​		在实验框架中，我们直接删除了所有包含缺失值的数据：

```python
data_df = data_df.dropna()
```

这会不会损失部分资料呢？尤其是框架中打印的前三行，都是比较有名的学校且有缺失值，因此为了打消顾虑，仔细检查下数据集。原来每所学校都有三年的打分数据，缺失的数据全都是 2012 年的 broad_impact，而这部分学校同时也有 2013-2015 的数据，因此删掉没有影响。删除之后，还剩两年 2000 条数据。

### 2.2 线性相关性的观察

​		因为目标是建立一个线性模型，首要关注的是各个自变量是否真的与因变量之间存在近似的线性关系。因此，我将每个自变量和因变量花在一张图上，代码如下：

```python
info_names = ['world_rank', 'national_rank', 'quality_of_education', 'alumni_employment', 'quality_of_faculty', 'publications', 'influence',
              'citations', 'broad_impact', 'patents']
str_names =  ['institution', 'region']

for info in info_names: # 对于每个特征名字
    fig, axs = plt.subplots(1, 1, figsize=(10,5))
    plt_data = data_df[[info, 'score']]
    # sns.set(rc={'axes.facecolor':'grey', 'figure.facecolor':'white'})
    # sns.set_palette("ch:s=-.2,r=.6", 8, color_codes=True)
    sns.set_palette("hls", 8, color_codes=True)
    sns.set_theme(style="ticks", rc={"axes.spines.right": False, "axes.spines.top": False})
    sns.regplot(x=info, y='score', data=plt_data)
    plt.savefig('./reports/' + info + '.pdf')
```

以下是一个典型的结果：

![influence](fig/influence.pdf)

这不像线性关系，而像是对数关系。因此尝试打开回归的 log选项：

![influence_log](fig/influence_log.pdf)

这个看上去靠谱多了。这提示我们回归的时候要考虑给自变量做对数变换。

​		另一个值得一提的是数据项 `national_rank`。不难猜测这个特征可能很难用到回归中去，但是画图后可以发现，其实只需恰当的二分类就可以使用这个特征了，它和所处地区必然有关。这提示我们可以进行相关尝试。

![national_rank_log](fig/national_rank_log.pdf)

### 2.3 多重共线性的观察

​		多元回归模型另一个重要的影响性能的指标就是多重共线性。为此，我们绘制数据集相关系数矩阵的热力图如下：

![heat](fig/heat_f.pdf)

代码如下：

```python
# 生成对数项
feature_cols = ['quality_of_faculty', 'publications', 'citations', 'alumni_employment',
                'influence', 'quality_of_education', 'broad_impact', 'patents']
data_df = data_df[feature_cols]
for column in feature_cols:
    data_df['log_' + column] = np.log2(data_df[column])

corr = data_df.corr()
sns.heatmap(corr, fmt="f", linewidths=.5, annot=True, ax=ax)
```

从这里看出比较优质的特征有 `alumni_employment` 和 `patents`，它们的颜色比较深；而特征 `broad_impact` 与很多别的特征都有较强的关联，因此后续研究过程中考虑将它去除。注意，相关程度高不一定就是多重共线性，因此还需要观察统计数据来证明。



# 三、回归分析

### 3.1 重复试验的框架

​		相关代码见 source/base.py。

​		先使用 sklearn 的框架搭建一个可进行回归的模型

```python
X = data_df[feature_cols].values
Y = data_df['score'].values
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)

lr = LinearRegression()
lr.fit(x_train, y_train)

print(lr.coef_)

RMSE = 0
for sample, label in zip(x_test, y_test):
    y_hat = lr.predict(sample.reshape(1, -1))
    RMSE += pow(label - y_hat, 2)

RMSE = np.sqrt(RMSE/len(y_test))
print(RMSE)
```

得到系数和 RMSE：

```
[-0.06252249  0.00029599 -0.00014474 -0.00711777  0.00038911 -0.00619858 -0.00233552 -0.00254875]
[3.52121046]
```

这个结果收到训练集和测试集划分的影响，因此需要多次重复检验。重复框架如下：

```python
total_RMSE = []
REPEAT_TIMES = 10000

for i in range(0, REPEAT_TIMES):
    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)

    lr = LinearRegression()
    lr.fit(x_train, y_train)

    RMSE = 0
    for sample, label in zip(x_test, y_test):
        y_hat = lr.predict(sample.reshape(1, -1))
        RMSE += pow(label - y_hat, 2)

    RMSE = np.sqrt(RMSE / len(y_test))
    total_RMSE.append(RMSE[0])

mean = sum(total_RMSE) / REPEAT_TIMES
print(mean)

plt.xlim([min(total_RMSE) - 0.5, max(total_RMSE) + 0.5])
plt.hist(total_RMSE, bins=30)
plt.title('Test Set RMSE Frequency')
plt.xlabel('RMSE')
plt.ylabel('freq.')
plt.savefig('RMSE_hist.pdf')
```

每次重复都重新选取训练集和测试集。得到平均 RMSE 为 4.2226，最大 RMSE 为 6.4659，最小 RMSE 为 6.4658，频率直方图为

![](fig/RMSE_hist.pdf)

​		只需对 X 做变换即可实现对数化处理，所使用代码如下：

```python
log = np.vectorize(np.log)
X = log(X)
```

再使用上述代码，得到平均 RMSE 为 2.3543，频率直方图为

![](fig/RMSE_log_hist.pdf)

可以看出自变量的对数参与回归，效果比直接线性回归好了不少。



### 3.2 回归系数的分析框架

​		相关代码见 source/coef.py。

​		为了方便对回归系数的分析，我采用了 statsmodels 包的相关函数。这个包的使用也相当简单，回归分析的框架如下：

```python
inv = sm.add_constant(x_train)  # 加入常数项
mu = sm.OLS(y_train, inv)  # 因变量，自变量
est = mu.fit()

print(est.summary())
```

但是如此使用 np.ndarray 没有变量名称，不适合使用。因此，我对数据集做进一步处理：

```python
Y_train = train_df["score"]
Y_test = test_df["score"]

feature_cols = ['quality_of_faculty', 'publications', 'citations', 'alumni_employment',
                'influence', 'quality_of_education', 'broad_impact', 'patents']
for column in feature_cols:
    train_df['log_' + column] = np.log2(train_df[column])
    test_df['log_' + column] = np.log2(test_df[column])

def cal_RMSE(coef, X_test):
    RMSE = 0
    for row, label in zip(X_test,Y_test):
        x_use = np.insert(row, 0, 1)
        hat_y = np.dot(x_use, coef)
        RMSE += pow(label-hat_y, 2)

    RMSE = np.sqrt(RMSE / len(y_test))
    print('RMSE= ', RMSE)
```

于是，可以用下列代码执行回归并计算 RMSE：

```python
X = train_df[cols]
X = sm.add_constant(X)
M = sm.OLS(Y_train, X)
E = M.fit()

print(E.summary())

X_test = test_df[cols].values
cal_RMSE(E.params, X_test)
```

其中 cols 是选取的特征列。分别对上节两个回归选取同一个训练集进行分析，得到结果如下：

```
cols = feature_cols

std_out:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  score   R-squared:                       0.596
Model:                            OLS   Adj. R-squared:                  0.594
Method:                 Least Squares   F-statistic:                     293.5
Date:                Sun, 03 Apr 2022   Prob (F-statistic):          1.19e-306
Time:                        18:05:03   Log-Likelihood:                -4597.9
No. Observations:                1600   AIC:                             9214.
Df Residuals:                    1591   BIC:                             9262.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
========================================================================================
                           coef    std err          t      P>|t|      [0.025      0.975]
----------------------------------------------------------------------------------------
const                   66.1695      0.426    155.330      0.000      65.334      67.005
quality_of_faculty      -0.0662      0.003    -21.969      0.000      -0.072      -0.060
publications             0.0002      0.001      0.243      0.808      -0.002       0.002
citations             1.699e-05      0.001      0.020      0.984      -0.002       0.002
alumni_employment       -0.0069      0.001     -9.079      0.000      -0.008      -0.005
influence                0.0007      0.001      0.780      0.436      -0.001       0.003
quality_of_education    -0.0060      0.001     -3.980      0.000      -0.009      -0.003
broad_impact            -0.0026      0.001     -1.966      0.049      -0.005   -6.15e-06
patents                 -0.0025      0.001     -4.669      0.000      -0.004      -0.001
==============================================================================
Omnibus:                     1344.217   Durbin-Watson:                   2.033
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            49411.546
Skew:                           3.723   Prob(JB):                         0.00
Kurtosis:                      29.186   Cond. No.                     5.22e+03
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
[2] The condition number is large, 5.22e+03. This might indicate that there are
strong multicollinearity or other numerical problems.
RMSE=  3.9588631253563733
```

```
cols = ['log_'+col for col in feature_cols]

std_out:
                            OLS Regression Results                            
==============================================================================
Dep. Variable:                  score   R-squared:                       0.882
Model:                            OLS   Adj. R-squared:                  0.882
Method:                 Least Squares   F-statistic:                     1494.
Date:                Sun, 03 Apr 2022   Prob (F-statistic):               0.00
Time:                        18:06:40   Log-Likelihood:                -3610.1
No. Observations:                1600   AIC:                             7238.
Df Residuals:                    1591   BIC:                             7287.
Df Model:                           8                                         
Covariance Type:            nonrobust                                         
============================================================================================
                               coef    std err          t      P>|t|      [0.025      0.975]
--------------------------------------------------------------------------------------------
const                      101.4632      0.528    192.144      0.000     100.427     102.499
log_quality_of_faculty      -3.5930      0.130    -27.538      0.000      -3.849      -3.337
log_publications            -0.0075      0.140     -0.054      0.957      -0.281       0.266
log_citations               -0.1251      0.132     -0.952      0.341      -0.383       0.133
log_alumni_employment       -1.3007      0.063    -20.678      0.000      -1.424      -1.177
log_influence               -0.0813      0.154     -0.527      0.598      -0.384       0.221
log_quality_of_education    -0.7447      0.096     -7.741      0.000      -0.933      -0.556
log_broad_impact            -0.5720      0.207     -2.769      0.006      -0.977      -0.167
log_patents                 -0.5032      0.062     -8.172      0.000      -0.624      -0.382
==============================================================================
Omnibus:                      699.177   Durbin-Watson:                   2.017
Prob(Omnibus):                  0.000   Jarque-Bera (JB):            16265.043
Skew:                           1.500   Prob(JB):                         0.00
Kurtosis:                      18.329   Cond. No.                         217.
==============================================================================

Notes:
[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.
RMSE=  2.4115927046045162
```

为了方便叙述，我们称使用原始变量做回归的模型为 (1)，称使用自变量对数做回归的模型为 (2)。通过对 R2、F 统计量、标准误和 P 值的分析，可以发现模型 (1) 中存在严重的多重共线性，主要涉及的变量为 publications、citations、influence 和 broad_impact 这四个，通过其含义也不难发现它们具有相关性。而在模型 (2) 中，整体的回归质量有所提升，但是在 publications、citations 和 influence 之间存在的多重共线性仍然显著。因此，我们先围绕后三个变量进行分析。



### 3.3 回归模型比较的分析框架

​		相关代码见 source/feature_selection.py。

​		为了比较不同的回归模型，我们主要关注的是回归系数及其标准误、R2、F 统计量以及 RMSE。上述 summary 函数输出的内容太多，不容易比较。为了方便观察和排除过拟合现象，不妨花一点时间建立一个分析框架，设置验证集，提取上述所需的特征并制表。相关代码如下：

1. 验证集的设置

   ```python
   data_df = pd.read_csv('./cwurData.csv')  # 读入 csv 文件为 pandas 的 DataFrame
   data_df = data_df.dropna()  # 舍去包含 NaN 的 row
   
   # 划分训练集与测试集
   train_df = data_df.sample(frac=0.8)
   test_df = data_df.drop(train_df.index)
   
   # 在训练集中划出验证集
   _train_df = train_df.sample(frac=0.8)
   _validation_df = train_df.drop(_train_df.index)
   
   # 获取标签: 标签是全程不需要特殊处理的
   Y_train = _train_df["score"]
   Y_val = _validation_df["score"].values
   Y_test = test_df["score"].values
   
   # 生成对数项
   feature_cols = ['quality_of_faculty', 'publications', 'citations', 'alumni_employment',
                   'influence', 'quality_of_education', 'broad_impact', 'patents']
   for column in feature_cols:
       _train_df['log_' + column] = np.log2(_train_df[column])
       _validation_df['log_' + column] = np.log2(_validation_df[column])
       test_df['log_' + column] = np.log2(test_df[column])
   ```

2. 重新设置 RMSE 计算函数的接口

   ```python
   def cal_RMSE(coef, X, Y):  # 透过系数计算 RMSE, 因为特征选取不一定一致, 需要传入 X 和 Y
       RMSE = 0
       for row, label in zip(X, Y):
           x_use = np.insert(row, 0, 1)  # 加常数项
           hat_y = np.dot(x_use, coef)
           RMSE += pow(label-hat_y, 2)
   
       RMSE = np.sqrt(RMSE / len(Y))
       return RMSE
   ```

3. 把模型训练封装成函数

   ```python
   def _evaluate(col):  # Y = w·X[col]
   
       X = _train_df[col]  # 获取训练数据
       X = sm.add_constant(X)  # 加入常数项
       M = sm.OLS(Y_train, X)
       E = M.fit()
       X_val = _validation_df[col].values
   
       return E, cal_RMSE(E.params, X_val, Y_val)
   ```

4. 通过阅读 summary 函数源代码找到上述所需信息的存储位置（这个库的文档真的啥都没写）

   ```
   R-squared: self.rsquared
   Adjusted R-squared: self.rsquared_adj
   F-statistic: self.fvalue
   Prob (F-statistic): self.f_pvalue
   
   制表相关信息在调用的 Summary.summary_params_2dflat 中
   coef: res.params
   std err: res.bse
   t: res.tvalues
   P>|t|: res.pvalues
   Confident Inverval [0.025 0.975]: res.conf_int(alpha=0.05)
   ```

5. 设置控制信息

   ```python
   model_base = ['const',
                 'log_quality_of_faculty', 'log_alumni_employment',
                 'log_quality_of_education', 'log_broad_impact', 'log_patents',
                 'publications', 'citations', 'influence',
                 'log_publications', 'log_citations', 'log_influence']  # 当前全体特征
   
   targets = [
       ['log_quality_of_faculty', 'log_alumni_employment', 'log_quality_of_education', 'log_broad_impact', 'log_patents']
       ..., 
       ['log_quality_of_faculty', 'log_alumni_employment', 'log_quality_of_education', 'log_broad_impact', 'log_patents',
        'publications', 'citations', 'influence', 'log_publications', 'log_citations', 'log_influence'],
   ]
   ```

   其中 targets 每一行对应一个需要评估的模型。

6. 实现输出相关函数

   ```python
   def print_head():  # 第一列
       field_width = max([len(name) for name in model_base]) + 3
       lines = [' ' * field_width]
       for name in model_base:
           lines.append('-' * field_width)
           lines.append(name + (' ' * (field_width - len(name))))
           lines.append(' ' * field_width)
       lines.append('-' * field_width)
       for name in controls:
           lines.append(name + (' ' * (field_width - len(name))))
   
       return lines
   ```

   ```python
   def print_sample(order, col, est, RMSE):  # 每一列 15 格
       lines = []
       # 标题：______(1)______
       if order < 10:
           title = (" " * 6) + "(" + str(order) + ")" + (" " * 6)
       else:
           title = (" " * 5) + "(" + str(order) + ")" + (" " * 6)
       lines.append(title)
   
       # const
       lines.append('-' * 15)
       num_part = '%10.3f' % est.params[0]
       if est.pvalues[0] < 0.01:
           star_part = '***  '
       elif est.pvalues[0] < 0.05:
           star_part = '**   '
       elif est.pvalues[0] < 0.1:
           star_part = '*    '
       else:
           star_part = '     '
       lines.append(num_part + star_part)
       se = '%.3f' % est.bse[0]
       se_part = (' ' * (8 - len(se))) + '(' + se + ')' + (' ' * 5)
       lines.append(se_part)
   
       # 其他特征
       for feature in model_base[1:]:
           lines.append('-' * 15)
           if feature in col:  # 被模型选择
               index = col.index(feature) + 1  # 出现顺序
               num_part = '%10.4f' % est.params[index]
               if est.pvalues[index] < 0.01:
                   star_part = '***  '
               elif est.pvalues[index] < 0.05:
                   star_part = '**   '
               elif est.pvalues[index] < 0.1:
                   star_part = '*    '
               else:
                   star_part = '     '
               lines.append(num_part + star_part)
               se = '%.3f' % est.bse[index]
               se_part = (' ' * (8 - len(se))) + '(' + se + ')' + (' ' * 5)
               lines.append(se_part)
           else:  # 被跳过的特征
               lines.append((' ' * 7) + '-' + (' ' * 7))
               lines.append(' ' * 15)
   
       lines.append('-' * 15)
       lines.append('%10.4f' % est.rsquared_adj + '     ')
       lines.append('%10.4f' % est.fvalue + '     ')
       lines.append('%10.4f' % RMSE + '     ')
   
       return lines
   ```

7. 批量训练回归模型并输出

   ```python
   order = 1
   results = [print_head()]
   for col in targets:
       est, rmse = _evaluate(col)
       results.append(print_sample(order, col, est, rmse))
       order += 1
   
   line_num = len(results[0])
   text = [''] * line_num
   for line_no in range(0, line_num):
       for col in results:
           text[line_no] += col[line_no]
   
   with open('feature_selection.txt', mode='wt') as f:
       for line in text:
           f.write(line + '\n')
       f.write("\nNote: Standard error in the parentheses.")
   ```

基于上述代码，得到结果如下：

![result](/Users/xi/Downloads/fig/result.png)

上述结果保存于 source/feature_selection_opt1.txt。

​		再去除掉 model_base 和 targets 中全部的 broad_impact 后运行上述代码，得到结果如下：

![result2](/Users/xi/Downloads/fig/result2.png)

上述结果保存于 source/feature_selection_opt2.txt。

​		在这么多个模型中选择主要的依据有二：

1. 拟合的好不好，包括 R2 是否接近 1，F 统计量是否够大，回归系数是否都显著，这反映了所选用的参数表现的好坏。
2. 泛化能力强不强，主要参考 RMSE 的大小。

从上述结果中，不难发现以上两个依据是相互拮抗的，即通常拟合优度很好的模型泛化能力会差一些。这要求我们对模型对数据的表示能力和泛化能力之间做出取舍。首先，肯定要排除回归系数不显著、F 统计量比较低的模型，其次，再选择 RMSE 较低的模型，进行重复试验验证。最后，在效能差不多的情况下，根据奥卡姆剃刀的原则，选取其中较为简单的模型。

​		根据以上原则，我选中了三个模型，分别是第二张图的 (1) 和两张图的 (25)。均进行一万次重复试验，结果如下：

- 模型 (2-1)，RMSE 最小 1.7132，最大 3.4996，平均 2.4209。与基准模型基本持平。
- 模型 (1-25)，RMSE 最小 1.4948，最大 3.1021，平均 2.1573。明显优于基准模型。
- 模型 (2-25)，RMSE 最小 1.5608，最大 3.0545，平均 2.1566。明显优于上述两个模型。

因此，我们选择模型 (2-25) 作为最终模型，它平均的泛化误差更小，且分布更为集中。模型内容为
$$
y=\beta_0+\beta_1 \log (\text{quality of faculty}) + \beta_2\log (\text{alumni employment}) + \beta_3\log (\text{quality of education}) + \beta_4\log (\text{patents}) +\beta_5 (\text{influence}) + \beta_6 \log (\text{influence})
$$
模型平均 RMSE 为 2.1566。



# 四、地区信息的引入

### 4.1 数据集划分

​		之前提到，数据项 `national_rank` 分为两类，且一类分显著高于另一类，且回归的线没有被上半部分带偏，说明上半部分数据点数较少，合理怀疑两部分分别是美国和世界。因此将数据集划分后分别做图观察：

```python
flag = data_df.region == 'USA'
data_USA = data_df[flag]
data_NUSA = data_df[~flag]

fig, axs = plt.subplots(1, 2, figsize=(15,5))
plt_data = data_USA[['national_rank', 'score']]
plt_data2 = data_NUSA[['national_rank', 'score']]
sns.set_palette("hls", 8, color_codes=True)
sns.set_theme(style="ticks", rc={"axes.spines.right": False, "axes.spines.top": False})
sns.regplot(x='national_rank', y='score', data=plt_data, logx=True, ax = axs[0])
sns.regplot(x='national_rank', y='score', data=plt_data2, logx=True, ax = axs[1])

plt.savefig('./reports/national_rank_Split_log.pdf')
```

![](fig/national_rank_Split_log.pdf)

由此可以看出美国国内的确实符合观察到的特征，而其他国家的可能也值得进行一个分类。但是大部分国家的数据量偏少，而且单个国家也没有特别符合对数特征。不妨先用当前分类，在上述 (2-25) 模型的基础上进行一个尝试。



### 4.2 分类回归的实现

​		相关代码见 source/nation.py。

​		要实现这一分类，在上述框架的基础上，加入以下修改

```python
train_df = data_df.sample(frac=0.8)
test_df = data_df.drop(train_df.index)

flag = train_df.region == 'USA'
data_USA = train_df[flag]
data_NUSA = train_df[~flag]

x1_train = data_USA[choose].values
y1_train = data_USA['score'].values
x2_train = data_NUSA[choose].values
y2_train = data_NUSA['score'].values  # 拆分训练集

x_test = test_df[choose].values
y_test = test_df['score'].values
x_flag = (test_df['region'] == 'USA').values  # 给测试集额外传入一个 flag

lr1 = LinearRegression()
lr2 = LinearRegression()
lr1.fit(x1_train, y1_train)
lr2.fit(x2_train, y2_train)  # 两类分别训练线性回归模型

RMSE = 0
for sample, label, flag in zip(x_test, y_test, x_flag):  # 依据 flag 选择一个模型预测
  y_hat = lr1.predict(sample.reshape(1, -1)) if flag else lr2.predict(sample.reshape(1, -1))
  RMSE += pow(label - y_hat, 2)
```

choose 的设置与上述模型系统。同样一万次重复试验，得到 RMSE 最小 1.4219，最大 3.2156，平均 1.9836。这个模型得到巨大的进步。



### 4.3 多分类回归的实现

​		相关代码见 source/nation2.py。

​		如果要实现更多的国家分开回归，按照同样的框架可以继续进行，先以将样本数不到一百的国家单独取做一个类，主要框架如下：

```python
flag1 = train_df.region == 'USA'
data_USA = train_df[flag1]
data_NUSA = train_df[~flag1]

flag2 = data_NUSA.region == 'China'
data_CN = data_NUSA[flag2]
data_NCN = data_NUSA[~flag2]

flag3 = data_NCN.region == 'Japan'
data_JP = data_NCN[flag3]
data_NJP = data_NCN[~flag3]

flag4 = data_NCN.region == 'United Kingdom'
data_UK = data_NCN[flag4]
data_NUK = data_NCN[~flag4]

flag5 = data_NCN.region == 'Germany'
data_GM = data_NCN[flag5]
data_OT = data_NCN[~flag5]

x1_train = data_USA[choose].values
y1_train = data_USA['score'].values
x2_train = data_CN[choose].values
y2_train = data_CN['score'].values
x3_train = data_JP[choose].values
y3_train = data_JP['score'].values
x4_train = data_UK[choose].values
y4_train = data_UK['score'].values
x5_train = data_GM[choose].values
y5_train = data_GM['score'].values
x6_train = data_OT[choose].values
y6_train = data_OT['score'].values

x_test = test_df[choose].values
y_test = test_df['score'].values
x_flag = (test_df['region'] == 'USA').values

lr1 = LinearRegression()
lr2 = LinearRegression()
lr3 = LinearRegression()
lr4 = LinearRegression()
lr5 = LinearRegression()
lr6 = LinearRegression()

lr1.fit(x1_train, y1_train)
lr2.fit(x2_train, y2_train)
lr3.fit(x3_train, y3_train)
lr4.fit(x4_train, y4_train)
lr5.fit(x5_train, y5_train)
lr6.fit(x6_train, y6_train)

RMSE = 0
for sample, label, flag in zip(x_test, y_test, x_flag):
  if flag == 'USA':
    	y_hat = lr1.predict(sample.reshape(1, -1))
  elif flag == 'China':
      y_hat = lr2.predict(sample.reshape(1, -1))
  elif flag == 'Japan':
      y_hat = lr3.predict(sample.reshape(1, -1))
  elif flag == 'United Kingdom':
      y_hat = lr4.predict(sample.reshape(1, -1))
  elif flag == 'Germany':
      y_hat = lr5.predict(sample.reshape(1, -1))
  else:
      y_hat = lr6.predict(sample.reshape(1, -1))
RMSE += pow(label - y_hat, 2)
RMSE = np.sqrt(RMSE / len(y_test))
```

得到 RMSE 最小 1.4262，最大 3.8926，平均 2.2151。分布明显出现长尾的特征，说明部分国家可能因为样本太少，单独分类起了反效果。

​		上述逻辑删除部分即可得到取部分国家为单独类别的模型。只保留美国和中国之后，得到 RMSE 最小 1.3336，最大 4.0759，平均 2.2366。因此，最终还是 4.2 节实现的模型更优。




# 五、小结

​		本次实验获得的最优平均 RMSE 为 1.9836，模型为
$$
y=\beta_0+\beta_1 \log (\text{quality of faculty}) + \beta_2\log (\text{alumni employment}) + \beta_3\log (\text{quality of education}) + \beta_4\log (\text{patents}) +\beta_5 (\text{influence}) + \beta_6 \log (\text{influence}) + \beta_7\log(\text{national rank})
$$
对美国和非美国学校分别进行回归。模型实现位于 source/nation.py 中。

​		因为设置的重复实验次数很多，为减少助教验证工作，特将所有实验过程保存在 source/exp2_local_history.ipynb 中，以供参考。该文件包含了每一次有价值的输出（特定几次小问题就直接改了，没有再运行保存）。文件比较杂乱，仅建议在查询结果是否真实以及查看没有包含的图像时使用，最终以实验报告为准。















